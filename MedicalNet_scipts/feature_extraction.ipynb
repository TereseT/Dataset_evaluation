{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract image features using pretrained MedicalNet models\n",
    "\n",
    "Explanation of how to extract features from image datasets to use for dataset analysis using the Silhouette score or the Frechet inception distance (FID). \n",
    "\n",
    "### Install MedicalNet\n",
    "\n",
    "This code relies on the MedicalNet github repository. In order to extract image features using MedicalNet models MedicalNet first needs to be installed. Intructions for this can be found on their github repository at https://github.com/Tencent/MedicalNet. \n",
    "\n",
    "### Adapt MedicalNet for feature extraction\n",
    "\n",
    "In order to use the MedicalNet model to extract image features to use for dataset evaluation the script 'extract_features.py' needs to be used instead of the test.py script. Add this file to the MedicalNet-master mainfolder and adapt to your dataset. \n",
    "\n",
    "### Create txt files of data paths\n",
    "\n",
    "In order to get the image features for the two separate classes two files need to be made which contain the paths for each data sample of each class. This will be used by the MedicalNet model for feature extraction. \n",
    "\n",
    "To make these txt files, use the scripts below. \n",
    "\n",
    "If you run into memory issues during processing, the feature extraction can be split into smaller sets using the large_dataset=True option in the 'extract_features.py' script. To use this option you need to split your dataset txt file into multiple files named \"dataset_0_A.txt\" \"dataset_0_B.txt\" etc to process part of the dataset at a time. \n",
    "\n",
    "### Extract features and reduce dimentionality using global average pooling (GPA) and PCA\n",
    "\n",
    "Use the 'extract_features.py' code to extract features with MedicalNet followed by reducing the dimentionality using GPA and PCA functions. This creates a featurevectors for each sample. These are saved based on the given savepath hardcoded in the extract_features.py file. \n",
    "\n",
    "To extract features this way apply the following command in ther terminal for your dataset:\n",
    "\n",
    "```python /extract_features.py --img_list '/Dataset_ovarian/Preprocessed_data_FAST' --input_H 256 --input_W 256 --resume_path '/pretrain/resnet_50_23dataset.pth' --gpu_id 0```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths for project\n",
    "\n",
    "# Ovarian paths\n",
    "data_p = './Dataset_ovarian'\n",
    "preprocessed_p = './Dataset_ovarian/Preprocessed_data_RADIOMICS'\n",
    "\n",
    "# Pancreas paths\n",
    "data_p = './Pancreas_cropped'\n",
    "preprocessed_p = './Pancreas_cropped/Preprocessed_data_RADIOMICS'\n",
    "\n",
    "\n",
    "# LIDC paths \n",
    "data_p = './NIFTI-LIDC'\n",
    "preprocessed_p = './NIFTI-LIDC/Preprocessed_data_RADIOMICS'\n",
    "\n",
    "# Liver dataset paths\n",
    "data_p = './Liver_LITS17'\n",
    "preprocessed_p = './Liver_LITS17/Preprocessed_data_RADIOMICS'\n",
    "\n",
    "# FractureMNIST3D\n",
    "data_p = './MedMNIST/FractureMNIST3D'\n",
    "preprocessed_p = './MedMNIST/FractureMNIST3D/Preprocessed_data_RADIOMICS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_csv_path = os.path.join(preprocessed_p, 'preprocessed_data.csv')\n",
    "#Save paths for dataset path files for each class\n",
    "save_path_txt_0 = os.path.join(preprocessed_p, 'dataset_0.txt')\n",
    "save_path_txt_1 = os.path.join(preprocessed_p, 'dataset_1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make txt files for dataset\n",
    "\n",
    "df = pd.read_csv(dataset_csv_path, usecols=['image_path', 'label'] )\n",
    "im_paths_0 = []\n",
    "im_paths_1 = []\n",
    "print(enumerate(df.iterrows()))\n",
    "for index, row in df.iterrows():\n",
    "    print('index', index)\n",
    "    image_path = row['image_path']\n",
    "    label = row['label']\n",
    "    if str(label) == '0':\n",
    "        im_paths_0.append(image_path)\n",
    "    \n",
    "    elif str(label) == '1':\n",
    "        im_paths_1.append(image_path)\n",
    "    else:\n",
    "        print(f'Label not recognized! Label: {label}, type: {type(label)}')\n",
    "        continue\n",
    "\n",
    "print('class 0', len(im_paths_0), im_paths_0)\n",
    "print('class 1', len(im_paths_1), im_paths_1)\n",
    "\n",
    "\n",
    "with open(save_path_txt_0, \"w\") as outfile:\n",
    "    outfile.write(\"\\n\".join(im_paths_0))\n",
    "\n",
    "print('class 1')\n",
    "print('save', save_path_txt_0)\n",
    "\n",
    "with open(save_path_txt_1, \"w\") as outfile:\n",
    "    outfile.write(\"\\n\".join(im_paths_1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_python3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
